spring.config.activate.on-profile=manual

# Hibernate Properties
# The SQL dialect makes Hibernate generate better SQL for the chosen database
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

# Database parameters
spring.datasource.url=jdbc:postgresql://localhost:5432/sampledb?characterEncoding=utf8&useSSL=false
spring.datasource.username=sampledb_user
spring.datasource.password=password
spring.liquibase.enabled=false

# can be used to disable the Whitelabel Error Page
server.error.whitelabel.enabled=false

spring.main.allow-bean-definition-overriding=true

## Configs of spring-cloud-aws
#cloud.aws.stack.auto=false
#cloud.aws.region.auto=false
#cloud.aws.region.static=us-east-1
#spring.config.import= optional:aws-parameterstore:
#aws.paramstore.prefix=/config
#aws.paramstore.defaultContext=application
#aws.paramstore.profileSeparator=_
#aws.paramstore.name=sysco-bootstrap-java_dev

# Configs of spring-cloud-aws
cloud.aws.region.static=us-east-1
cloud.aws.stack.auto=false
aws.paramstore.name=bt-perso-analytics
spring.config.import=optional:aws-parameterstore:/config/

# Application Ids
application.client.id=id
application.client.secret=secret

spring.batch.initialize-schema=ALWAYS
perks.fee.update.cron.expression=0 0 0 L-1 * *
perks.eligible.opco.list="123,234"
spring.batch.job.enabled=false

# Required connection configs for Confluent Cloud Schema Registry
spring.kafka.properties.schema.registry.url=url
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.basic.auth.user.info=password

#S3 upload config
dtc.offers.s3.bucket.name="name"
dtc.offers.s3.bucket.key="key"

#CRM API configuration
oauth.token.url="token url"
crm.api.v3.base.url="api url"
salesforce.case.recordTypeId="type id"
salesforce.case.ownerId="owner id"
salesforce.lineItem.perksFee.supc="supc id"
